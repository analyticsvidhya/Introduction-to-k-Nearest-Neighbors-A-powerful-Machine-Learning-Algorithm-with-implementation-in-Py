{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation in Python from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Start of STEP 1\n",
    "# Importing data \n",
    "data = pd.read_csv(\"iris.csv\")\n",
    "#### End of STEP 1\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function which calculates euclidean distance between two data points\n",
    "def euclideanDistance(data1, data2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance += np.square(data1[x] - data2[x])\n",
    "    return np.sqrt(distance)\n",
    "\n",
    "# Defining our KNN model\n",
    "def knn(trainingSet, testInstance, k):\n",
    " \n",
    "    distances = {}\n",
    "    sort = {}\n",
    " \n",
    "    length = testInstance.shape[1]\n",
    "    \n",
    "    #### Start of STEP 3\n",
    "    # Calculating euclidean distance between each row of training data and test data\n",
    "    for x in range(len(trainingSet)):\n",
    "        \n",
    "        #### Start of STEP 3.1\n",
    "        dist = euclideanDistance(testInstance, trainingSet.iloc[x], length)\n",
    "\n",
    "        distances[x] = dist[0]\n",
    "        #### End of STEP 3.1\n",
    " \n",
    "    #### Start of STEP 3.2\n",
    "    # Sorting them on the basis of distance\n",
    "    sorted_d = sorted(distances.items(), key=operator.itemgetter(1))\n",
    "    #### End of STEP 3.2\n",
    " \n",
    "    neighbors = []\n",
    "    \n",
    "    #### Start of STEP 3.3\n",
    "    # Extracting top k neighbors\n",
    "    for x in range(k):\n",
    "        neighbors.append(sorted_d[x][0])\n",
    "    #### End of STEP 3.3\n",
    "    classVotes = {}\n",
    "    \n",
    "    #### Start of STEP 3.4\n",
    "    # Calculating the most freq class in the neighbors\n",
    "    for x in range(len(neighbors)):\n",
    "        response = trainingSet.iloc[neighbors[x]][-1]\n",
    " \n",
    "        if response in classVotes:\n",
    "            classVotes[response] += 1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    #### End of STEP 3.4\n",
    "\n",
    "    #### Start of STEP 3.5\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return(sortedVotes[0][0], neighbors)\n",
    "    #### End of STEP 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dummy testset\n",
    "testSet = [[7.2, 3.6, 5.1, 2.5]]\n",
    "test = pd.DataFrame(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Start of STEP 2\n",
    "# Setting number of neighbors = 1\n",
    "k = 1\n",
    "#### End of STEP 2\n",
    "# Running KNN model\n",
    "result,neigh = knn(data, test, k)\n",
    "\n",
    "# Predicted class\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest neighbor\n",
    "print(neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting number of neighbors = 3 \n",
    "k = 3 \n",
    "# Running KNN model \n",
    "result,neigh = knn(data, test, k) \n",
    "# Predicted class \n",
    "print(result) -> Iris-virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 nearest neighbors\n",
    "print(neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting number of neighbors = 5\n",
    "k = 5\n",
    "# Running KNN model \n",
    "result,neigh = knn(data, test, k) \n",
    "# Predicted class \n",
    "print(result) -> Iris-virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 nearest neighbors\n",
    "print(neigh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing our model with scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(data.iloc[:,0:4], data['Name'])\n",
    "\n",
    "# Predicted class\n",
    "print(neigh.predict(test))\n",
    "\n",
    "# 3 nearest neighbors\n",
    "print(neigh.kneighbors(test)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of kNN in R "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data and calculating the data summary\n",
    "\n",
    "data<-read.table(file.choose(), header = T, sep = \",\", dec = \".\")#Importing the data \n",
    "head(data)  #Top observations present in the data\n",
    "dim(data)   #Check the dimensions of the data\n",
    "summary(data) #Summarise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data set into train and test\n",
    "set.seed(2)\n",
    "\n",
    "part <- sample(2, nrow(data), replace = TRUE, prob = c(0.7, 0.3))\n",
    "\n",
    "train<- data[part == 1,]\n",
    "\n",
    "test<- data[part == 2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the euclidean distance\n",
    "\n",
    "ED<-function(data1,data2){\n",
    "distance=0\n",
    "  for (i in (1:(length(data1)-1))){\n",
    "    distance=distance+(data1[i]-data2[i])^2\n",
    "  }\n",
    "  return(sqrt(distance))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing the function to predict kNN\n",
    "knn_predict <- function(test, train, k_value){\n",
    "  pred <- c()  \n",
    "  #LOOP-1\n",
    "  for(i in c(1:nrow(test))){   \n",
    "    dist = c()          \n",
    "    char = c()\n",
    "    setosa =0              \n",
    "    versicolor = 0\n",
    "    virginica = 0\n",
    "  }\n",
    "    \n",
    "    #LOOP-2-looping over train data \n",
    "    for(j in c(1:nrow(train))){}\n",
    "      \n",
    "      dist <- c(dist, ED(test[i,], train[j,]))\n",
    "      char <- c(char, as.character(train[j,][[5]]))\n",
    "    \n",
    "  \n",
    "    df <- data.frame(char, dist$SepalLength) \n",
    "    df <- df[order(df$dist.SepalLength),]       #sorting dataframe\n",
    "    df <- df[1:k_value,]               \n",
    "    \n",
    "    \n",
    "    #Loop 3: loops over df and counts classes of neibhors.\n",
    "    for(k in c(1:nrow(df))){\n",
    "      if(as.character(df[k,\"char\"]) == \"setosa\"){\n",
    "        setosa = setosa + 1\n",
    "      }else if(as.character(df[k,\"char\"]) == \"versicolor\"){\n",
    "        versicolor = versicolor + 1\n",
    "      }else\n",
    "        virginica = virginica + 1\n",
    "    }\n",
    "    \n",
    "    \n",
    "    n<-table(df$char)\n",
    "    pred=names(n)[which(n==max(n))]\n",
    "    \n",
    "  return(pred) #return prediction vector\n",
    "}\n",
    "\n",
    "#Predicting the value for K=1\n",
    "K=1\n",
    "predictions <- knn_predict(test, train, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing our kNN predictor function with “Class” library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"class\")\n",
    "library(class)\n",
    "\n",
    "#Normalization\n",
    "normalize <- function(x) {\n",
    "  return ((x - min(x)) / (max(x) - min(x))) }\n",
    "norm <- as.data.frame(lapply(data[,1:4], normalize))\n",
    "\n",
    "set.seed(123)\n",
    "data_spl <- sample(1:nrow(norm),size=nrow(norm)*0.7,replace = FALSE) \n",
    "\n",
    "train2 <- data[data_spl,] # 70% training data\n",
    "test2 <- data[-data_spl,] # remaining 30% test data\n",
    "\n",
    "train_labels <- data[data_spl,5]\n",
    "test_labels <-data[-data_spl,5]\n",
    "knn_pred <- knn(train=train2, test=test2, cl=train_labels, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
